{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import Dataset\nimport torchvision\nfrom torchvision import datasets,transforms\nfrom torchvision.transforms import ToTensor\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom PIL import Image\nimport albumentations as A\nfrom tqdm import tqdm\nimport torch.optim as optim\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.preprocessing import OneHotEncoder\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:24.175689Z","iopub.execute_input":"2023-09-13T10:50:24.176027Z","iopub.status.idle":"2023-09-13T10:50:29.602574Z","shell.execute_reply.started":"2023-09-13T10:50:24.175998Z","shell.execute_reply":"2023-09-13T10:50:29.601587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train  = pd.read_csv(\"/kaggle/input/train-images-doodle-detectives/train.csv\")\ndf_train.info(memory_usage=\"deep\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:29.604477Z","iopub.execute_input":"2023-09-13T10:50:29.604962Z","iopub.status.idle":"2023-09-13T10:50:34.270421Z","shell.execute_reply.started":"2023-09-13T10:50:29.604921Z","shell.execute_reply":"2023-09-13T10:50:34.269295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image, ImageDraw\nimport numpy as np\nimport json\n\ndef vector_to_numpy(drawing, side=256):\n    image = vector_to_image(drawing, side)\n    image_array = np.array(image)\n    return image_array\n\ndef vector_to_image(drawing, side=256):\n    drawing = json.loads(drawing)\n    min_x, min_y, max_x, max_y = calculate_bounding_box(drawing)\n\n    # Calculate the offset to center the drawing within the canvas\n    offset_x = (side - (max_x - min_x + 1)) // 2\n    offset_y = (side - (max_y - min_y + 1)) // 2\n\n    image = Image.new('L', (side, side), color='white')  # Create a white canvas\n    draw = ImageDraw.Draw(image)\n\n    for x, y in drawing:\n        xy = [(x0 - min_x + offset_x, y0 - min_y + offset_y) for x0, y0 in zip(x, y)]\n        draw.line(xy, fill='black', width=1)\n\n    return image\n\ndef calculate_bounding_box(drawing):\n    all_x = [x for x, _ in drawing]\n    all_y = [y for _, y in drawing]\n\n    min_x = min(min(x) for x in all_x)\n    min_y = min(min(y) for y in all_y)\n    max_x = max(max(x) for x in all_x)\n    max_y = max(max(y) for y in all_y)\n\n    return min_x, min_y, max_x, max_y\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:34.272205Z","iopub.execute_input":"2023-09-13T10:50:34.272574Z","iopub.status.idle":"2023-09-13T10:50:34.284666Z","shell.execute_reply.started":"2023-09-13T10:50:34.272540Z","shell.execute_reply":"2023-09-13T10:50:34.283771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[\"word\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:34.287645Z","iopub.execute_input":"2023-09-13T10:50:34.288273Z","iopub.status.idle":"2023-09-13T10:50:34.360515Z","shell.execute_reply.started":"2023-09-13T10:50:34.288240Z","shell.execute_reply":"2023-09-13T10:50:34.359472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#one hot encoding of labels\ndef one_hot_enc(df_train):\n        df_train['word'] = df_train['word'].astype('category')  \n        # Assigning numerical values and storing it in another columns\n        df_train['word_new'] = df_train['word'].cat.codes\n        # Create an instance of One-hot-encoder\n        enc = OneHotEncoder()\n        # Passing encoded columns\n        enc_data = enc.fit_transform(\n            df_train[['word_new']]).toarray()\n        return enc_data\n    \nenc_data = one_hot_enc(df_train)\nenc_data","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:34.363617Z","iopub.execute_input":"2023-09-13T10:50:34.363860Z","iopub.status.idle":"2023-09-13T10:50:34.898977Z","shell.execute_reply.started":"2023-09-13T10:50:34.363838Z","shell.execute_reply":"2023-09-13T10:50:34.897772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_HEIGHT = 256\nIMAGE_WIDTH  = 256  \ntrain_transform = A.Compose(\n        [\n            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n            A.Rotate(limit=35, p=1.0),\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.1),\n            A.Normalize(\n                mean=[0.0],\n                std=[1.0],\n                max_pixel_value=255.0,\n            ),\n            ToTensorV2(),\n        ],\n    )\n\nval_transform = A.Compose(\n        [\n            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n            A.Normalize(\n                mean=[0.0],\n                std=[1.0],\n                max_pixel_value=255.0,\n            ),\n            ToTensorV2(),\n        ],\n    )","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:34.900935Z","iopub.execute_input":"2023-09-13T10:50:34.901327Z","iopub.status.idle":"2023-09-13T10:50:34.910509Z","shell.execute_reply.started":"2023-09-13T10:50:34.901292Z","shell.execute_reply":"2023-09-13T10:50:34.909447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating a dataset\nclass train_images(Dataset):\n    def __init__(self,X,Y,transform):\n        self.dataframe = X\n        self.transform = transform\n        self.encodings = Y\n        \n    '''def one_hot_enc(self,df_train):\n        df_train['word'] = df_train['word'].astype('category')  \n        # Assigning numerical values and storing it in another columns\n        df_train['word_new'] = df_train['word'].cat.codes\n        # Create an instance of One-hot-encoder\n        enc = OneHotEncoder()\n        # Passing encoded columns\n        enc_data = enc.fit_transform(\n            df_train[['word_new']]).toarray()\n        return enc_data'''\n        \n    def __len__(self):\n        return len(self.dataframe)\n    def __getitem__(self, idx):\n        train_image = vector_to_numpy(self.dataframe.iloc[idx][\"drawing\"])\n        train_image = 1 - self.transform(image = train_image)[\"image\"].reshape((1,256,256))   #.to(DEVICE)\n        label       = torch.tensor(self.encodings.iloc[idx])\n        return train_image,label\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:34.911979Z","iopub.execute_input":"2023-09-13T10:50:34.912616Z","iopub.status.idle":"2023-09-13T10:50:34.922085Z","shell.execute_reply.started":"2023-09-13T10:50:34.912583Z","shell.execute_reply":"2023-09-13T10:50:34.921070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating a dataset\nclass test_images(Dataset):\n    def __init__(self,X,transform):\n        self.dataframe = X\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.dataframe)\n    \n    def __getitem__(self, idx):\n        train_image = vector_to_numpy(self.dataframe.iloc[idx][\"drawing\"])\n        train_image = 1 - self.transform(image = train_image)[\"image\"].reshape((1,256,256))   #.to(DEVICE)\n        return train_image\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:34.924444Z","iopub.execute_input":"2023-09-13T10:50:34.925078Z","iopub.status.idle":"2023-09-13T10:50:34.938754Z","shell.execute_reply.started":"2023-09-13T10:50:34.925003Z","shell.execute_reply":"2023-09-13T10:50:34.937899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class EMSRB(nn.Module):\n#     def __init__(self,input_channels,num_features,f1,f2):\n#         super().__init__()\n#         self.ic    = input_channels\n#         self.conv3_1 = nn.Conv2d(in_channels = self.ic, out_channels=num_features,kernel_size = f1)\n#         self.conv5_1 = nn.Conv2d(in_channels = self.ic, out_channels=num_features,kernel_size = f2,padding=1)\n#         self.conv1_1 = nn.Conv2d(in_channels = self.ic, out_channels=num_features,kernel_size = 1)\n\n#         self.relu  = nn.ReLU()\n\n#         self.conv3_2 = nn.Conv2d(in_channels = 2* num_features, out_channels=num_features,kernel_size = f1)\n#         self.conv5_2 = nn.Conv2d(in_channels = 2* num_features, out_channels=num_features,kernel_size = f2,padding=1)\n#         self.conv1_2 = nn.Conv2d(in_channels = 2* num_features, out_channels=num_features,kernel_size = 1,padding=self.get_padding(f1,f2))\n    \n#     def get_padding(self,f1,f2):\n#         if f1 == 5 and f2 == 7:\n#             return 4\n#         else:\n#             return 2\n\n#     def forward(self,input):\n\n#         in_path1 = self.relu(self.conv3_1(input))\n#         #print(in_path1.shape)\n#         in_path2 = self.relu(self.conv5_1(input))\n#         #print(in_path2.shape)\n#         concat_features = torch.cat(tensors = (in_path1,in_path2),dim = 1)\n#         #print(concat_features.shape)\n#         in_path1 = self.relu(self.conv3_2(concat_features))\n#         #print(in_path1.shape)\n#         in_path2 = self.relu(self.conv5_2(concat_features))\n#         #print(in_path2.shape)\n#         concat_features = torch.cat(tensors = (in_path1,in_path2),dim = 1)\n#         #print(concat_features.shape)\n#         concat_features = self.conv1_2(concat_features)\n#         #print(concat_features.shape)\n#         in_ = self.conv1_1(input)\n#         #print(in_.shape)\n#         concat_features = concat_features+in_\n#         #print(concat_features.shape)\n#         return concat_features","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:34.941603Z","iopub.execute_input":"2023-09-13T10:50:34.941934Z","iopub.status.idle":"2023-09-13T10:50:34.951823Z","shell.execute_reply.started":"2023-09-13T10:50:34.941902Z","shell.execute_reply":"2023-09-13T10:50:34.950925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Custom_nn(nn.Module):\n    def __init__(self,Net_size = 256,input_shape = 512, output_shape =101):\n        super().__init__()\n        self.nn = nn.Sequential(nn.Linear(input_shape,Net_size),nn.Tanh(),\n                                nn.Linear(Net_size,output_shape))\n        \n    def forward(self,input):\n        return (self.nn(input))\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:34.955485Z","iopub.execute_input":"2023-09-13T10:50:34.955756Z","iopub.status.idle":"2023-09-13T10:50:34.966821Z","shell.execute_reply.started":"2023-09-13T10:50:34.955734Z","shell.execute_reply":"2023-09-13T10:50:34.965866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import torchvision.models as models\n\n# model_EMSRB1  = EMSRB(1,16,5,7)\n# model_EMSRB2  = EMSRB(16,3,3,5)\n# model_resent = models.resnet18(pretrained=True)\n# model_resent = nn.Sequential(*list(model_resent.children())[:-1])\n# model_custom = Custom_nn(input_shape = 512)\n# for params in model_resent.parameters():\n#     params.requires_grad = False\n\n# class final_model(nn.Module):\n#     def __init__(self,model_EMSRB1,model_EMSRB2,model_resent,model_custom):\n#         super().__init__()\n#         self.model1    = model_EMSRB1\n#         self.model2    = model_EMSRB2\n#         self.resnet    = model_resent\n#         for param in self.resnet.parameters():\n#             param.requires_grad = False\n#         self.model4    = model_custom\n#     def forward(self,input):\n        \n#         out = self.model1(input)\n#         out = self.model2(out)\n#         out = self.resnet(out)\n#         #print(out.shape)\n#         out = self.model4(out.reshape(out.shape[0],out.shape[1]*out.shape[2]*out.shape[3] ))\n#         #print(out.shape)\n#         return out\n    \n# model_final = final_model(model_EMSRB1,model_EMSRB2,model_resent,model_custom)\n# model_final","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:34.967891Z","iopub.execute_input":"2023-09-13T10:50:34.968141Z","iopub.status.idle":"2023-09-13T10:50:34.982146Z","shell.execute_reply.started":"2023-09-13T10:50:34.968120Z","shell.execute_reply":"2023-09-13T10:50:34.981239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a = torch.randn(size = (8,1,256,256))\n# model_final(a).shape","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:34.985138Z","iopub.execute_input":"2023-09-13T10:50:34.985423Z","iopub.status.idle":"2023-09-13T10:50:34.993324Z","shell.execute_reply.started":"2023-09-13T10:50:34.985376Z","shell.execute_reply":"2023-09-13T10:50:34.992514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train,X_val, y_train,y_val = train_test_split(df_train,df_train['word_new'],test_size = 0.3,shuffle = True,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:34.994890Z","iopub.execute_input":"2023-09-13T10:50:34.995229Z","iopub.status.idle":"2023-09-13T10:50:35.070851Z","shell.execute_reply.started":"2023-09-13T10:50:34.995199Z","shell.execute_reply":"2023-09-13T10:50:35.069945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape,y_train.shape,X_val.shape,y_val.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:35.071992Z","iopub.execute_input":"2023-09-13T10:50:35.074251Z","iopub.status.idle":"2023-09-13T10:50:35.082303Z","shell.execute_reply.started":"2023-09-13T10:50:35.074218Z","shell.execute_reply":"2023-09-13T10:50:35.081333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keys = X_train[\"word\"]\nvalues = X_train[\"word_new\"]\ndict_ = {}\nfor i in range(len(keys)):\n    dict_[values.iloc[i]] = keys.iloc[i]\n\ndict_\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:35.083643Z","iopub.execute_input":"2023-09-13T10:50:35.085598Z","iopub.status.idle":"2023-09-13T10:50:43.711068Z","shell.execute_reply.started":"2023-09-13T10:50:35.085573Z","shell.execute_reply":"2023-09-13T10:50:43.703288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df_train","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:43.712254Z","iopub.execute_input":"2023-09-13T10:50:43.712622Z","iopub.status.idle":"2023-09-13T10:50:43.744341Z","shell.execute_reply.started":"2023-09-13T10:50:43.712588Z","shell.execute_reply":"2023-09-13T10:50:43.741011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = train_images(X_train,y_train, train_transform)\ntrain_image,label = train_dataset.__getitem__(0)\nplt.imshow(train_image.numpy().reshape(256,256))\nlabel","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:43.746130Z","iopub.execute_input":"2023-09-13T10:50:43.746567Z","iopub.status.idle":"2023-09-13T10:50:44.219226Z","shell.execute_reply.started":"2023-09-13T10:50:43.746526Z","shell.execute_reply":"2023-09-13T10:50:44.218280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:44.223476Z","iopub.execute_input":"2023-09-13T10:50:44.225760Z","iopub.status.idle":"2023-09-13T10:50:44.236674Z","shell.execute_reply.started":"2023-09-13T10:50:44.225724Z","shell.execute_reply":"2023-09-13T10:50:44.235716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = test_images(X_val,val_transform)\ntrain_image = test_dataset.__getitem__(244)\nplt.imshow(train_image.numpy().reshape(256,256))","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:44.244351Z","iopub.execute_input":"2023-09-13T10:50:44.247000Z","iopub.status.idle":"2023-09-13T10:50:44.598643Z","shell.execute_reply.started":"2023-09-13T10:50:44.246966Z","shell.execute_reply":"2023-09-13T10:50:44.597621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data_loaders\ndef get_loaders(train_dataset,val_dataset,batch_size = 32):\n\n    train_dataset = train_dataset\n    val_dataset   = val_dataset\n    train_loader  = torch.utils.data.DataLoader(train_dataset,batch_size = batch_size, num_workers = 2,shuffle = True)\n    val_loader    = torch.utils.data.DataLoader(val_dataset,batch_size = batch_size, num_workers = 2)\n    return train_loader,val_loader","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:44.606740Z","iopub.execute_input":"2023-09-13T10:50:44.609644Z","iopub.status.idle":"2023-09-13T10:50:44.617668Z","shell.execute_reply.started":"2023-09-13T10:50:44.609608Z","shell.execute_reply":"2023-09-13T10:50:44.616831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_accuracy(loader, model, device=\"cuda\"):\n    model.eval()\n    criteria = nn.CrossEntropyLoss()\n    count,loss = 0,0\n    with torch.no_grad():\n        for x, y in loader: \n            count+=1\n            if count>=10:\n                break\n            x = x.to(device)\n            y = y.type(torch.LongTensor).to(device)\n            preds = (model(x))\n            loss  += criteria(preds,y)\n\n    print(f\"loss: {loss/(count)}\")\n    model.train()\n    return loss/count","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:44.622198Z","iopub.execute_input":"2023-09-13T10:50:44.622566Z","iopub.status.idle":"2023-09-13T10:50:44.634682Z","shell.execute_reply.started":"2023-09-13T10:50:44.622540Z","shell.execute_reply":"2023-09-13T10:50:44.633719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_ = check_accuracy(val_loader, model, device=DEVICE)\nloss_","metadata":{"execution":{"iopub.status.busy":"2023-09-13T09:43:52.681136Z","iopub.execute_input":"2023-09-13T09:43:52.681628Z","iopub.status.idle":"2023-09-13T09:43:52.938120Z","shell.execute_reply.started":"2023-09-13T09:43:52.681597Z","shell.execute_reply":"2023-09-13T09:43:52.937003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef train_fn(loader, model, optimizer, loss_fn, scaler,loss_arr):\n    loop = tqdm(loader)\n    \n    GLOBAL_COUNT = 0\n    for batch_idx, (data, targets) in enumerate(loop):\n        data = data.to(DEVICE)\n        targets = targets.type(torch.LongTensor).to(DEVICE)\n        #print(targets,targets.shape)\n        # forward\n        with torch.cuda.amp.autocast():\n            predictions = model(data)\n            #print(predictions,predictions.shape)\n            loss = loss_fn(predictions, targets)\n            loss_arr.append(loss.item())\n        # backward\n        optimizer.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        if GLOBAL_COUNT%100 == 0:\n            if GLOBAL_COUNT%500 == 0 :\n                print(\"model_saved\")\n            save_path = \"model.pth\"\n            torch.save(model.state_dict(),save_path)\n            GLOBAL_COUNT+=1\n\n        # update tqdm loop\n        loop.set_postfix(loss=loss.item())\n    return loss_arr","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:44.638993Z","iopub.execute_input":"2023-09-13T10:50:44.639639Z","iopub.status.idle":"2023-09-13T10:50:44.653327Z","shell.execute_reply.started":"2023-09-13T10:50:44.639603Z","shell.execute_reply":"2023-09-13T10:50:44.652458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass UNetEncoder(nn.Module):\n    def __init__(self, in_channels, bottleneck_channels):\n        super(UNetEncoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(in_channels, 64, kernel_size=9, padding=0),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=7, padding=0),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2)\n        )\n        self.conv1 = self.conv_block(64, 128)\n        self.conv2 = self.conv_block(128, 256)\n        self.conv3 = self.conv_block(256, 512)\n        self.conv4 = self.conv_block(512, bottleneck_channels)\n    \n    def conv_block(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(out_channels, out_channels, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=0),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=1)\n        )\n\n    def forward(self, x):\n        x1 = self.encoder(x)\n        x2 = self.conv1(x1)\n        x3 = self.conv2(x2)\n        x4 = self.conv3(x3)\n        x5 = self.conv4(x4)\n        return x5\n\n# Example usage:\nin_channels = 1  # Number of input channels (e.g., for RGB images)\nbottleneck_channels = 512  # Number of channels in the bottleneck\nencoder = UNetEncoder(in_channels, bottleneck_channels)\nmodel_custom = Custom_nn(input_shape = 512)\nclass final_model_unet(nn.Module):\n    def __init__(self,encoder,model_custom):\n        super().__init__()\n        self.model1    = encoder\n        self.model2    = model_custom\n        \n    def forward(self,input):\n        \n        out = self.model1(input)\n        out = self.model2(out.reshape(out.shape[0],out.shape[1]*out.shape[2]*out.shape[3]))\n        return out\n    \nmodel_final_unet = final_model_unet(encoder,model_custom)\nmodel_final_unet","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:44.658662Z","iopub.execute_input":"2023-09-13T10:50:44.661060Z","iopub.status.idle":"2023-09-13T10:50:45.027233Z","shell.execute_reply.started":"2023-09-13T10:50:44.661027Z","shell.execute_reply":"2023-09-13T10:50:45.026330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = torch.randn(size = (8,1,256,256))\nmodel_final_unet(a).shape","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:50:47.639913Z","iopub.execute_input":"2023-09-13T10:50:47.640257Z","iopub.status.idle":"2023-09-13T10:50:52.034321Z","shell.execute_reply.started":"2023-09-13T10:50:47.640228Z","shell.execute_reply":"2023-09-13T10:50:52.033341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nLEARNING_RATE = 1e-5\n# model_final_unet = final_model_unet(encoder,model_custom)\n# model_final_unet.load_state_dict(torch.load(\"/kaggle/working/model.pth\"))\nmodel = model_final_unet.to(DEVICE)\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:51:00.344086Z","iopub.execute_input":"2023-09-13T10:51:00.344495Z","iopub.status.idle":"2023-09-13T10:51:03.159997Z","shell.execute_reply.started":"2023-09-13T10:51:00.344462Z","shell.execute_reply":"2023-09-13T10:51:03.159036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#datasets\ntrain_dataset = train_images(X_train,y_train, train_transform)\nval_dataset   = train_images(X_val,y_val, val_transform)\ntrain_loader, val_loader = get_loaders(train_dataset,val_dataset,batch_size = 32)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T10:51:08.715441Z","iopub.execute_input":"2023-09-13T10:51:08.715882Z","iopub.status.idle":"2023-09-13T10:51:08.722345Z","shell.execute_reply.started":"2023-09-13T10:51:08.715847Z","shell.execute_reply":"2023-09-13T10:51:08.721401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = torch.cuda.amp.GradScaler()\nloss_epoch = []\n\nfor epoch in range(100):\n        loss_epoch = train_fn(train_loader, model, optimizer, loss_fn, scaler,loss_epoch)\n        try:\n            print(\"First epoch\")\n            save_path = \"model.pth\"\n            torch.save(model.state_dict(),save_path)\n            loss_ = check_accuracy(val_loader, model, device=DEVICE)\n            loss_epoch.append(loss_)\n        except:\n            continue","metadata":{"execution":{"iopub.status.busy":"2023-09-13T11:45:43.530058Z","iopub.execute_input":"2023-09-13T11:45:43.530786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_dummy = final_model(model_EMSRB1,model_EMSRB2,model_resent,model_custom)\nmodel_dummy.load_state_dict(torch.load(\"/kaggle/working/model.pth\"))\nmodel_dummy","metadata":{"execution":{"iopub.status.busy":"2023-09-13T09:43:02.011403Z","iopub.execute_input":"2023-09-13T09:43:02.011679Z","iopub.status.idle":"2023-09-13T09:43:02.337820Z","shell.execute_reply.started":"2023-09-13T09:43:02.011652Z","shell.execute_reply":"2023-09-13T09:43:02.336366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p = [[0.1,0.4,0.5],[0,0,1]]\ny = [2,1]\ncross = 0\nfor true in range(len(y)):\n    logits = p[true]\n    soft_logits = np.exp(logits)/np.sum(np.exp(logits))\n    print(soft_logits)\n    print(y[true])\n    cross += -np.log(soft_logits[y[true]])\ncross/len(y)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T16:35:47.878397Z","iopub.execute_input":"2023-09-12T16:35:47.878911Z","iopub.status.idle":"2023-09-12T16:35:47.893694Z","shell.execute_reply.started":"2023-09-12T16:35:47.878875Z","shell.execute_reply":"2023-09-12T16:35:47.892096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"-np.log(0)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T16:36:00.915136Z","iopub.execute_input":"2023-09-12T16:36:00.915675Z","iopub.status.idle":"2023-09-12T16:36:00.927912Z","shell.execute_reply.started":"2023-09-12T16:36:00.915640Z","shell.execute_reply":"2023-09-12T16:36:00.925847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}