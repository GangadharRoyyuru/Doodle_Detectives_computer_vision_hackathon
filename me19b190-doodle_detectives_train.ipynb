{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "AU-lE9WldU6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision\n",
        "from torchvision import datasets,transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:24.175689Z",
          "iopub.execute_input": "2023-09-13T10:50:24.176027Z",
          "iopub.status.idle": "2023-09-13T10:50:29.602574Z",
          "shell.execute_reply.started": "2023-09-13T10:50:24.175998Z",
          "shell.execute_reply": "2023-09-13T10:50:29.601587Z"
        },
        "trusted": true,
        "id": "SRAXta6NdU6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the training dataset\n",
        "df_train  = pd.read_csv(\"/kaggle/input/train-images-doodle-detectives/train.csv\")\n",
        "df_train.info(memory_usage=\"deep\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:29.604477Z",
          "iopub.execute_input": "2023-09-13T10:50:29.604962Z",
          "iopub.status.idle": "2023-09-13T10:50:34.270421Z",
          "shell.execute_reply.started": "2023-09-13T10:50:29.604921Z",
          "shell.execute_reply": "2023-09-13T10:50:34.269295Z"
        },
        "trusted": true,
        "id": "1LnNbV5YdU6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using the given function to get the image from the given csv file\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "def vector_to_numpy(drawing, side=256):\n",
        "    image = vector_to_image(drawing, side)\n",
        "    image_array = np.array(image)\n",
        "    return image_array\n",
        "\n",
        "def vector_to_image(drawing, side=256):\n",
        "    drawing = json.loads(drawing)\n",
        "    min_x, min_y, max_x, max_y = calculate_bounding_box(drawing)\n",
        "\n",
        "    # Calculate the offset to center the drawing within the canvas\n",
        "    offset_x = (side - (max_x - min_x + 1)) // 2\n",
        "    offset_y = (side - (max_y - min_y + 1)) // 2\n",
        "\n",
        "    image = Image.new('L', (side, side), color='white')  # Create a white canvas\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    for x, y in drawing:\n",
        "        xy = [(x0 - min_x + offset_x, y0 - min_y + offset_y) for x0, y0 in zip(x, y)]\n",
        "        draw.line(xy, fill='black', width=1)\n",
        "\n",
        "    return image\n",
        "\n",
        "def calculate_bounding_box(drawing):\n",
        "    all_x = [x for x, _ in drawing]\n",
        "    all_y = [y for _, y in drawing]\n",
        "\n",
        "    min_x = min(min(x) for x in all_x)\n",
        "    min_y = min(min(y) for y in all_y)\n",
        "    max_x = max(max(x) for x in all_x)\n",
        "    max_y = max(max(y) for y in all_y)\n",
        "\n",
        "    return min_x, min_y, max_x, max_y\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:34.272205Z",
          "iopub.execute_input": "2023-09-13T10:50:34.272574Z",
          "iopub.status.idle": "2023-09-13T10:50:34.284666Z",
          "shell.execute_reply.started": "2023-09-13T10:50:34.272540Z",
          "shell.execute_reply": "2023-09-13T10:50:34.283771Z"
        },
        "trusted": true,
        "id": "7vsq2JcEdU6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[\"word\"].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:34.287645Z",
          "iopub.execute_input": "2023-09-13T10:50:34.288273Z",
          "iopub.status.idle": "2023-09-13T10:50:34.360515Z",
          "shell.execute_reply.started": "2023-09-13T10:50:34.288240Z",
          "shell.execute_reply": "2023-09-13T10:50:34.359472Z"
        },
        "trusted": true,
        "id": "iskSn-xxdU6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot encoding of labels\n",
        "def one_hot_enc(df_train):\n",
        "        df_train['word'] = df_train['word'].astype('category')\n",
        "        df_train['word_new'] = df_train['word'].cat.codes\n",
        "        enc = OneHotEncoder()\n",
        "        enc_data = enc.fit_transform(\n",
        "            df_train[['word_new']]).toarray()\n",
        "        return enc_data\n",
        "\n",
        "enc_data = one_hot_enc(df_train)\n",
        "enc_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:34.363617Z",
          "iopub.execute_input": "2023-09-13T10:50:34.363860Z",
          "iopub.status.idle": "2023-09-13T10:50:34.898977Z",
          "shell.execute_reply.started": "2023-09-13T10:50:34.363838Z",
          "shell.execute_reply": "2023-09-13T10:50:34.897772Z"
        },
        "trusted": true,
        "id": "EMJE4IgDdU6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#performing transforms on the given images\n",
        "IMAGE_HEIGHT = 256\n",
        "IMAGE_WIDTH  = 256\n",
        "train_transform = A.Compose(\n",
        "        [\n",
        "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "            A.Rotate(limit=35, p=1.0),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.1),\n",
        "            A.Normalize(\n",
        "                mean=[0.0],\n",
        "                std=[1.0],\n",
        "                max_pixel_value=255.0,\n",
        "            ),\n",
        "            ToTensorV2(),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "val_transform = A.Compose(\n",
        "        [\n",
        "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "            A.Normalize(\n",
        "                mean=[0.0],\n",
        "                std=[1.0],\n",
        "                max_pixel_value=255.0,\n",
        "            ),\n",
        "            ToTensorV2(),\n",
        "        ],\n",
        "    )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:34.900935Z",
          "iopub.execute_input": "2023-09-13T10:50:34.901327Z",
          "iopub.status.idle": "2023-09-13T10:50:34.910509Z",
          "shell.execute_reply.started": "2023-09-13T10:50:34.901292Z",
          "shell.execute_reply": "2023-09-13T10:50:34.909447Z"
        },
        "trusted": true,
        "id": "_8qsSxEidU6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a train dataset\n",
        "class train_images(Dataset):\n",
        "    def __init__(self,X,Y,transform):\n",
        "        self.dataframe = X\n",
        "        self.transform = transform\n",
        "        self.encodings = Y\n",
        "\n",
        "    '''def one_hot_enc(self,df_train):\n",
        "        df_train['word'] = df_train['word'].astype('category')\n",
        "        # Assigning numerical values and storing it in another columns\n",
        "        df_train['word_new'] = df_train['word'].cat.codes\n",
        "        # Create an instance of One-hot-encoder\n",
        "        enc = OneHotEncoder()\n",
        "        # Passing encoded columns\n",
        "        enc_data = enc.fit_transform(\n",
        "            df_train[['word_new']]).toarray()\n",
        "        return enc_data'''\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "    def __getitem__(self, idx):\n",
        "        train_image = vector_to_numpy(self.dataframe.iloc[idx][\"drawing\"])\n",
        "        train_image = 1 - self.transform(image = train_image)[\"image\"].reshape((1,256,256))   #.to(DEVICE)\n",
        "        label       = torch.tensor(self.encodings.iloc[idx])\n",
        "        return train_image,label\n",
        "\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:34.911979Z",
          "iopub.execute_input": "2023-09-13T10:50:34.912616Z",
          "iopub.status.idle": "2023-09-13T10:50:34.922085Z",
          "shell.execute_reply.started": "2023-09-13T10:50:34.912583Z",
          "shell.execute_reply": "2023-09-13T10:50:34.921070Z"
        },
        "trusted": true,
        "id": "DM3eEherdU6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a test dataset\n",
        "class test_images(Dataset):\n",
        "    def __init__(self,X,transform):\n",
        "        self.dataframe = X\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        train_image = vector_to_numpy(self.dataframe.iloc[idx][\"drawing\"])\n",
        "        train_image = 1 - self.transform(image = train_image)[\"image\"].reshape((1,256,256))   #.to(DEVICE)\n",
        "        return train_image\n",
        "\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:34.924444Z",
          "iopub.execute_input": "2023-09-13T10:50:34.925078Z",
          "iopub.status.idle": "2023-09-13T10:50:34.938754Z",
          "shell.execute_reply.started": "2023-09-13T10:50:34.925003Z",
          "shell.execute_reply": "2023-09-13T10:50:34.937899Z"
        },
        "trusted": true,
        "id": "RxWr9DnadU6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining a Custom neural network for the final predictions\n",
        "class Custom_nn(nn.Module):\n",
        "    def __init__(self,Net_size = 256,input_shape = 512, output_shape =101):\n",
        "        super().__init__()\n",
        "        self.nn = nn.Sequential(nn.Linear(input_shape,Net_size),nn.Tanh(),\n",
        "                                nn.Linear(Net_size,output_shape))\n",
        "\n",
        "    def forward(self,input):\n",
        "        return (self.nn(input))\n",
        "\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:34.955485Z",
          "iopub.execute_input": "2023-09-13T10:50:34.955756Z",
          "iopub.status.idle": "2023-09-13T10:50:34.966821Z",
          "shell.execute_reply.started": "2023-09-13T10:50:34.955734Z",
          "shell.execute_reply": "2023-09-13T10:50:34.965866Z"
        },
        "trusted": true,
        "id": "DdkmOnfddU6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a = torch.randn(size = (8,1,256,256))\n",
        "# model_final(a).shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:34.985138Z",
          "iopub.execute_input": "2023-09-13T10:50:34.985423Z",
          "iopub.status.idle": "2023-09-13T10:50:34.993324Z",
          "shell.execute_reply.started": "2023-09-13T10:50:34.985376Z",
          "shell.execute_reply": "2023-09-13T10:50:34.992514Z"
        },
        "trusted": true,
        "id": "m1Z5CD-6dU6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train-test-split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_val, y_train,y_val = train_test_split(df_train,df_train['word_new'],test_size = 0.3,shuffle = True,random_state=42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:34.994890Z",
          "iopub.execute_input": "2023-09-13T10:50:34.995229Z",
          "iopub.status.idle": "2023-09-13T10:50:35.070851Z",
          "shell.execute_reply.started": "2023-09-13T10:50:34.995199Z",
          "shell.execute_reply": "2023-09-13T10:50:35.069945Z"
        },
        "trusted": true,
        "id": "N7pwL_5kdU6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape,y_train.shape,X_val.shape,y_val.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:35.071992Z",
          "iopub.execute_input": "2023-09-13T10:50:35.074251Z",
          "iopub.status.idle": "2023-09-13T10:50:35.082303Z",
          "shell.execute_reply.started": "2023-09-13T10:50:35.074218Z",
          "shell.execute_reply": "2023-09-13T10:50:35.081333Z"
        },
        "trusted": true,
        "id": "X_wTifCtdU6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys = X_train[\"word\"]\n",
        "values = X_train[\"word_new\"]\n",
        "dict_ = {}\n",
        "for i in range(len(keys)):\n",
        "    dict_[values.iloc[i]] = keys.iloc[i]\n",
        "\n",
        "dict_\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:35.083643Z",
          "iopub.execute_input": "2023-09-13T10:50:35.085598Z",
          "iopub.status.idle": "2023-09-13T10:50:43.711068Z",
          "shell.execute_reply.started": "2023-09-13T10:50:35.085573Z",
          "shell.execute_reply": "2023-09-13T10:50:43.703288Z"
        },
        "trusted": true,
        "id": "1_8jGMHNdU6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del df_train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:43.712254Z",
          "iopub.execute_input": "2023-09-13T10:50:43.712622Z",
          "iopub.status.idle": "2023-09-13T10:50:43.744341Z",
          "shell.execute_reply.started": "2023-09-13T10:50:43.712588Z",
          "shell.execute_reply": "2023-09-13T10:50:43.741011Z"
        },
        "trusted": true,
        "id": "e9CpVem5dU6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sample code to check if the train data is working fine\n",
        "train_dataset = train_images(X_train,y_train, train_transform)\n",
        "train_image,label = train_dataset.__getitem__(0)\n",
        "plt.imshow(train_image.numpy().reshape(256,256))\n",
        "label"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:43.746130Z",
          "iopub.execute_input": "2023-09-13T10:50:43.746567Z",
          "iopub.status.idle": "2023-09-13T10:50:44.219226Z",
          "shell.execute_reply.started": "2023-09-13T10:50:43.746526Z",
          "shell.execute_reply": "2023-09-13T10:50:44.218280Z"
        },
        "trusted": true,
        "id": "Et7daC9qdU6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:44.223476Z",
          "iopub.execute_input": "2023-09-13T10:50:44.225760Z",
          "iopub.status.idle": "2023-09-13T10:50:44.236674Z",
          "shell.execute_reply.started": "2023-09-13T10:50:44.225724Z",
          "shell.execute_reply": "2023-09-13T10:50:44.235716Z"
        },
        "trusted": true,
        "id": "bJ_NYbDydU6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sample code to check if the test data is working fine\n",
        "\n",
        "test_dataset = test_images(X_val,val_transform)\n",
        "train_image = test_dataset.__getitem__(244)\n",
        "plt.imshow(train_image.numpy().reshape(256,256))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:44.244351Z",
          "iopub.execute_input": "2023-09-13T10:50:44.247000Z",
          "iopub.status.idle": "2023-09-13T10:50:44.598643Z",
          "shell.execute_reply.started": "2023-09-13T10:50:44.246966Z",
          "shell.execute_reply": "2023-09-13T10:50:44.597621Z"
        },
        "trusted": true,
        "id": "uQAPkWMmdU6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_loaders\n",
        "def get_loaders(train_dataset,val_dataset,batch_size = 32):\n",
        "\n",
        "    train_dataset = train_dataset\n",
        "    val_dataset   = val_dataset\n",
        "    train_loader  = torch.utils.data.DataLoader(train_dataset,batch_size = batch_size, num_workers = 2,shuffle = True)\n",
        "    val_loader    = torch.utils.data.DataLoader(val_dataset,batch_size = batch_size, num_workers = 2)\n",
        "    return train_loader,val_loader"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:44.606740Z",
          "iopub.execute_input": "2023-09-13T10:50:44.609644Z",
          "iopub.status.idle": "2023-09-13T10:50:44.617668Z",
          "shell.execute_reply.started": "2023-09-13T10:50:44.609608Z",
          "shell.execute_reply": "2023-09-13T10:50:44.616831Z"
        },
        "trusted": true,
        "id": "beGXml32dU6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#validation loss\n",
        "def check_accuracy(loader, model, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    criteria = nn.CrossEntropyLoss()\n",
        "    count,loss = 0,0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            count+=1\n",
        "            if count>=10:\n",
        "                break\n",
        "            x = x.to(device)\n",
        "            y = y.type(torch.LongTensor).to(device)\n",
        "            preds = (model(x))\n",
        "            loss  += criteria(preds,y)\n",
        "\n",
        "    print(f\"loss: {loss/(count)}\")\n",
        "    model.train()\n",
        "    return loss/count"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:44.622198Z",
          "iopub.execute_input": "2023-09-13T10:50:44.622566Z",
          "iopub.status.idle": "2023-09-13T10:50:44.634682Z",
          "shell.execute_reply.started": "2023-09-13T10:50:44.622540Z",
          "shell.execute_reply": "2023-09-13T10:50:44.633719Z"
        },
        "trusted": true,
        "id": "CagzHCCEdU6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_ = check_accuracy(val_loader, model, device=DEVICE)\n",
        "loss_"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T09:43:52.681136Z",
          "iopub.execute_input": "2023-09-13T09:43:52.681628Z",
          "iopub.status.idle": "2023-09-13T09:43:52.938120Z",
          "shell.execute_reply.started": "2023-09-13T09:43:52.681597Z",
          "shell.execute_reply": "2023-09-13T09:43:52.937003Z"
        },
        "trusted": true,
        "id": "9pLwN9SFdU6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training function\n",
        "def train_fn(loader, model, optimizer, loss_fn, scaler,loss_arr):\n",
        "    loop = tqdm(loader)\n",
        "\n",
        "    GLOBAL_COUNT = 0\n",
        "    for batch_idx, (data, targets) in enumerate(loop):\n",
        "        data = data.to(DEVICE)\n",
        "        targets = targets.type(torch.LongTensor).to(DEVICE)\n",
        "        #print(targets,targets.shape)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            predictions = model(data)\n",
        "            #print(predictions,predictions.shape)\n",
        "            loss = loss_fn(predictions, targets)#calculate loss\n",
        "            loss_arr.append(loss.item())\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        if GLOBAL_COUNT%100 == 0:\n",
        "            if GLOBAL_COUNT%500 == 0 :\n",
        "                print(\"model_saved\")\n",
        "            save_path = \"model.pth\"\n",
        "            torch.save(model.state_dict(),save_path)\n",
        "            GLOBAL_COUNT+=1\n",
        "\n",
        "        # update tqdm loop\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "    return loss_arr"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:44.638993Z",
          "iopub.execute_input": "2023-09-13T10:50:44.639639Z",
          "iopub.status.idle": "2023-09-13T10:50:44.653327Z",
          "shell.execute_reply.started": "2023-09-13T10:50:44.639603Z",
          "shell.execute_reply": "2023-09-13T10:50:44.652458Z"
        },
        "trusted": true,
        "id": "InB6aoJtdU6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining an encoder part of UNET\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class UNetEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, bottleneck_channels):\n",
        "        super(UNetEncoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=9, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=7, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        self.conv1 = self.conv_block(64, 128)\n",
        "        self.conv2 = self.conv_block(128, 256)\n",
        "        self.conv3 = self.conv_block(256, 512)\n",
        "        self.conv4 = self.conv_block(512, bottleneck_channels)\n",
        "\n",
        "    def conv_block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.encoder(x)\n",
        "        x2 = self.conv1(x1)\n",
        "        x3 = self.conv2(x2)\n",
        "        x4 = self.conv3(x3)\n",
        "        x5 = self.conv4(x4)\n",
        "        return x5\n",
        "\n",
        "in_channels = 1  # gray scale image\n",
        "bottleneck_channels = 512  # 512 features maps at the bottle neck\n",
        "encoder = UNetEncoder(in_channels, bottleneck_channels)\n",
        "model_custom = Custom_nn(input_shape = 512)\n",
        "class final_model_unet(nn.Module):\n",
        "    def __init__(self,encoder,model_custom):\n",
        "        super().__init__()\n",
        "        self.model1    = encoder\n",
        "        self.model2    = model_custom\n",
        "\n",
        "    def forward(self,input):\n",
        "\n",
        "        out = self.model1(input)\n",
        "        out = self.model2(out.reshape(out.shape[0],out.shape[1]*out.shape[2]*out.shape[3]))\n",
        "        return out\n",
        "\n",
        "model_final_unet = final_model_unet(encoder,model_custom)\n",
        "model_final_unet"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:44.658662Z",
          "iopub.execute_input": "2023-09-13T10:50:44.661060Z",
          "iopub.status.idle": "2023-09-13T10:50:45.027233Z",
          "shell.execute_reply.started": "2023-09-13T10:50:44.661027Z",
          "shell.execute_reply": "2023-09-13T10:50:45.026330Z"
        },
        "trusted": true,
        "id": "9atRNi1XdU6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(size = (8,1,256,256))\n",
        "model_final_unet(a).shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:47.639913Z",
          "iopub.execute_input": "2023-09-13T10:50:47.640257Z",
          "iopub.status.idle": "2023-09-13T10:50:52.034321Z",
          "shell.execute_reply.started": "2023-09-13T10:50:47.640228Z",
          "shell.execute_reply": "2023-09-13T10:50:52.033341Z"
        },
        "trusted": true,
        "id": "cV8HNscjdU6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "LEARNING_RATE = 1e-5\n",
        "# model_final_unet = final_model_unet(encoder,model_custom)\n",
        "# model_final_unet.load_state_dict(torch.load(\"/kaggle/working/model.pth\"))\n",
        "model = model_final_unet.to(DEVICE)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE) #initializing an Adam Optimizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:51:00.344086Z",
          "iopub.execute_input": "2023-09-13T10:51:00.344495Z",
          "iopub.status.idle": "2023-09-13T10:51:03.159997Z",
          "shell.execute_reply.started": "2023-09-13T10:51:00.344462Z",
          "shell.execute_reply": "2023-09-13T10:51:03.159036Z"
        },
        "trusted": true,
        "id": "4vYrZmOfdU6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#datasets\n",
        "train_dataset = train_images(X_train,y_train, train_transform)\n",
        "val_dataset   = train_images(X_val,y_val, val_transform)\n",
        "train_loader, val_loader = get_loaders(train_dataset,val_dataset,batch_size = 32)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:51:08.715441Z",
          "iopub.execute_input": "2023-09-13T10:51:08.715882Z",
          "iopub.status.idle": "2023-09-13T10:51:08.722345Z",
          "shell.execute_reply.started": "2023-09-13T10:51:08.715847Z",
          "shell.execute_reply": "2023-09-13T10:51:08.721401Z"
        },
        "trusted": true,
        "id": "h-th1AF1dU6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = torch.cuda.amp.GradScaler()\n",
        "loss_epoch = []\n",
        "#train function\n",
        "for epoch in range(100):\n",
        "        loss_epoch = train_fn(train_loader, model, optimizer, loss_fn, scaler,loss_epoch)\n",
        "        try:\n",
        "            print(\"First epoch\")\n",
        "            save_path = \"model.pth\"\n",
        "            torch.save(model.state_dict(),save_path)\n",
        "            loss_ = check_accuracy(val_loader, model, device=DEVICE)\n",
        "            loss_epoch.append(loss_)\n",
        "        except:\n",
        "            continue"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T11:45:43.530058Z",
          "iopub.execute_input": "2023-09-13T11:45:43.530786Z"
        },
        "trusted": true,
        "id": "d69ySJU7dU6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cross checking if the model saved is loading fine\n",
        "model_dummy = final_model(model_EMSRB1,model_EMSRB2,model_resent,model_custom)\n",
        "model_dummy.load_state_dict(torch.load(\"/kaggle/working/model.pth\"))\n",
        "model_dummy"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T09:43:02.011403Z",
          "iopub.execute_input": "2023-09-13T09:43:02.011679Z",
          "iopub.status.idle": "2023-09-13T09:43:02.337820Z",
          "shell.execute_reply.started": "2023-09-13T09:43:02.011652Z",
          "shell.execute_reply": "2023-09-13T09:43:02.336366Z"
        },
        "trusted": true,
        "id": "pkvRnW-wdU6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torchvision.models as models\n",
        "\n",
        "# model_EMSRB1  = EMSRB(1,16,5,7)\n",
        "# model_EMSRB2  = EMSRB(16,3,3,5)\n",
        "# model_resent = models.resnet18(pretrained=True)\n",
        "# model_resent = nn.Sequential(*list(model_resent.children())[:-1])\n",
        "# model_custom = Custom_nn(input_shape = 512)\n",
        "# for params in model_resent.parameters():\n",
        "#     params.requires_grad = False\n",
        "\n",
        "# class final_model(nn.Module):\n",
        "#     def __init__(self,model_EMSRB1,model_EMSRB2,model_resent,model_custom):\n",
        "#         super().__init__()\n",
        "#         self.model1    = model_EMSRB1\n",
        "#         self.model2    = model_EMSRB2\n",
        "#         self.resnet    = model_resent\n",
        "#         for param in self.resnet.parameters():\n",
        "#             param.requires_grad = False\n",
        "#         self.model4    = model_custom\n",
        "#     def forward(self,input):\n",
        "\n",
        "#         out = self.model1(input)\n",
        "#         out = self.model2(out)\n",
        "#         out = self.resnet(out)\n",
        "#         #print(out.shape)\n",
        "#         out = self.model4(out.reshape(out.shape[0],out.shape[1]*out.shape[2]*out.shape[3] ))\n",
        "#         #print(out.shape)\n",
        "#         return out\n",
        "\n",
        "# model_final = final_model(model_EMSRB1,model_EMSRB2,model_resent,model_custom)\n",
        "# model_final"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:34.967891Z",
          "iopub.execute_input": "2023-09-13T10:50:34.968141Z",
          "iopub.status.idle": "2023-09-13T10:50:34.982146Z",
          "shell.execute_reply.started": "2023-09-13T10:50:34.968120Z",
          "shell.execute_reply": "2023-09-13T10:50:34.981239Z"
        },
        "trusted": true,
        "id": "El0ecuK7dU6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class EMSRB(nn.Module):\n",
        "#     def __init__(self,input_channels,num_features,f1,f2):\n",
        "#         super().__init__()\n",
        "#         self.ic    = input_channels\n",
        "#         self.conv3_1 = nn.Conv2d(in_channels = self.ic, out_channels=num_features,kernel_size = f1)\n",
        "#         self.conv5_1 = nn.Conv2d(in_channels = self.ic, out_channels=num_features,kernel_size = f2,padding=1)\n",
        "#         self.conv1_1 = nn.Conv2d(in_channels = self.ic, out_channels=num_features,kernel_size = 1)\n",
        "\n",
        "#         self.relu  = nn.ReLU()\n",
        "\n",
        "#         self.conv3_2 = nn.Conv2d(in_channels = 2* num_features, out_channels=num_features,kernel_size = f1)\n",
        "#         self.conv5_2 = nn.Conv2d(in_channels = 2* num_features, out_channels=num_features,kernel_size = f2,padding=1)\n",
        "#         self.conv1_2 = nn.Conv2d(in_channels = 2* num_features, out_channels=num_features,kernel_size = 1,padding=self.get_padding(f1,f2))\n",
        "\n",
        "#     def get_padding(self,f1,f2):\n",
        "#         if f1 == 5 and f2 == 7:\n",
        "#             return 4\n",
        "#         else:\n",
        "#             return 2\n",
        "\n",
        "#     def forward(self,input):\n",
        "\n",
        "#         in_path1 = self.relu(self.conv3_1(input))\n",
        "#         #print(in_path1.shape)\n",
        "#         in_path2 = self.relu(self.conv5_1(input))\n",
        "#         #print(in_path2.shape)\n",
        "#         concat_features = torch.cat(tensors = (in_path1,in_path2),dim = 1)\n",
        "#         #print(concat_features.shape)\n",
        "#         in_path1 = self.relu(self.conv3_2(concat_features))\n",
        "#         #print(in_path1.shape)\n",
        "#         in_path2 = self.relu(self.conv5_2(concat_features))\n",
        "#         #print(in_path2.shape)\n",
        "#         concat_features = torch.cat(tensors = (in_path1,in_path2),dim = 1)\n",
        "#         #print(concat_features.shape)\n",
        "#         concat_features = self.conv1_2(concat_features)\n",
        "#         #print(concat_features.shape)\n",
        "#         in_ = self.conv1_1(input)\n",
        "#         #print(in_.shape)\n",
        "#         concat_features = concat_features+in_\n",
        "#         #print(concat_features.shape)\n",
        "#         return concat_features"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-13T10:50:34.941603Z",
          "iopub.execute_input": "2023-09-13T10:50:34.941934Z",
          "iopub.status.idle": "2023-09-13T10:50:34.951823Z",
          "shell.execute_reply.started": "2023-09-13T10:50:34.941902Z",
          "shell.execute_reply": "2023-09-13T10:50:34.950925Z"
        },
        "trusted": true,
        "id": "I0sMFKPjdU6m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}